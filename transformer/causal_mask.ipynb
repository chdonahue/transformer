{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook will implement a causal mask in the MultiHeadAttention class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    # TODO: Add causal and padding mask functionality\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False, causal_mask = False, padding_mask = False):\n",
    "        super().__init__()\n",
    "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = (\n",
    "            d_out // num_heads\n",
    "        )  # Reduce the projection dim to match desired output dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.causal_mask = causal_mask\n",
    "        self.padding_mask = padding_mask\n",
    "        self.register_buffer(\n",
    "            \"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x)  # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "        if self.causal_mask:\n",
    "            # Original mask truncated to the number of tokens and converted to boolean\n",
    "            mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "            # Use the mask to fill attention scores\n",
    "            attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "            print(attn_scores)\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1] ** 0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "\n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)  # optional projection\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_in = 768\n",
    "d_out = 768 # change this later\n",
    "context_length = 10\n",
    "dropout = 0.0\n",
    "num_heads = 6\n",
    "qkv_bias = False\n",
    "causal_mask = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "lang = \"en\"\n",
    "tokenizer_path = Path(f\"tokenizers/tokenizer_{lang}.json\")\n",
    "tokenizer = Tokenizer.from_file(str(tokenizer_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"[PAD]\").ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokenizer(version=\"1.0\", truncation=None, padding=None, added_tokens=[{\"id\":0, \"content\":\"[UNK]\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":1, \"content\":\"[PAD]\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":2, \"content\":\"[SOS]\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":3, \"content\":\"[EOS]\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}], normalizer=None, pre_tokenizer=Whitespace(), post_processor=None, decoder=None, model=WordLevel(vocab={\"[UNK]\":0, \"[PAD]\":1, \"[SOS]\":2, \"[EOS]\":3, \",\":4, \".\":5, \"e\":6, \"di\":7, \"che\":8, \"—\":9, \"’\":10, \"la\":11, \"non\":12, \"a\":13, \"il\":14, \"un\":15, \"in\":16, \"per\":17, \"si\":18, \";\":19, \"con\":20, \"una\":21, \"era\":22, \"le\":23, \"l\":24, \"mi\":25, \"ma\":26, \"è\":27, \"da\":28, \"'\":29, \"?\":30, \"del\":31, \"i\":32, \"come\":33, \"più\":34, \"della\":35, \"lo\":36, \"disse\":37, \"gli\":38, \"al\":39, \"aveva\":40, \"!\":41, \"se\":42, \":\":43, \"io\":44, \"alla\":45, \"d\":46, \"E\":47, \"lui\":48, \"questo\":49, \"sua\":50, \"me\":51, \"Ma\":52, \"tutto\":53, \"Non\":54, \"così\":55, \"nel\":56, \"mia\":57, \"egli\":58, \"Levin\":59, \"o\":60, \"cosa\":61, \"suo\":62, \"ne\":63, \"vi\":64, \"mio\":65, \"quando\":66, \"lei\":67, \"nella\":68, \"loro\":69, \"perché\":70, \"sono\":71, \"quella\":72, \"ad\":73, \"senza\":74, \"ci\":75, \"quel\":76, \"quello\":77, \"ed\":78, \"La\":79, \"delle\":80, \"Il\":81, \"su\":82, \"due\":83, \"mai\":84, \"prima\":85, \"erano\":86, \"ho\":87, \"ora\":88, \"tutti\":89, \"essere\":90, \"tempo\":91, \"uno\":92, \"dei\":93, \"stato\":94, \"sempre\":95, \"dopo\":96, \"dalla\":97, \"dal\":98, ...}, unk_token=\"[UNK]\"))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[27, 15636, 29]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "pad_token = tokenizer.encode(\"<pad>\")\n",
    "pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27, 15636, 29]\n"
     ]
    }
   ],
   "source": [
    "print(pad_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = MultiHeadAttention(d_in, d_out, context_length, dropout, num_heads, causal_mask=causal_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(3,10,d_in) # I think d_in is the dimension of the embedding? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.2853,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n",
      "          [ 0.1148,  0.8548,    -inf,  ...,    -inf,    -inf,    -inf],\n",
      "          [-0.3284,  0.1110,  0.5591,  ...,    -inf,    -inf,    -inf],\n",
      "          ...,\n",
      "          [ 0.2573,  0.4953,  0.6885,  ..., -0.6523,    -inf,    -inf],\n",
      "          [-0.1536,  0.2995,  0.2587,  ..., -1.3150,  0.1155,    -inf],\n",
      "          [-1.2021, -0.6269, -0.3970,  ..., -1.7746, -0.3770, -1.1426]],\n",
      "\n",
      "         [[-1.4818,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n",
      "          [-1.2557, -1.7559,    -inf,  ...,    -inf,    -inf,    -inf],\n",
      "          [-1.1673, -0.1226, -1.0296,  ...,    -inf,    -inf,    -inf],\n",
      "          ...,\n",
      "          [-1.0485, -1.3166, -1.3198,  ..., -1.8844,    -inf,    -inf],\n",
      "          [-1.1410, -0.0911, -0.8937,  ..., -2.1074, -0.1804,    -inf],\n",
      "          [-2.0097, -1.2315, -1.4400,  ..., -2.9487, -1.2072, -1.0436]],\n",
      "\n",
      "         [[-0.4530,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n",
      "          [-1.9940, -0.0998,    -inf,  ...,    -inf,    -inf,    -inf],\n",
      "          [-0.8288,  1.1694, -0.3014,  ...,    -inf,    -inf,    -inf],\n",
      "          ...,\n",
      "          [-1.0809, -0.0847, -0.6112,  ...,  0.1234,    -inf,    -inf],\n",
      "          [-1.3024,  0.6479, -0.3893,  ...,  0.7378,  0.0967,    -inf],\n",
      "          [-1.4345,  0.6352, -0.8335,  ..., -0.4635, -1.2992, -2.1746]],\n",
      "\n",
      "         [[-0.0826,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n",
      "          [-0.0948, -1.8797,    -inf,  ...,    -inf,    -inf,    -inf],\n",
      "          [ 0.1443, -0.9391, -0.1782,  ...,    -inf,    -inf,    -inf],\n",
      "          ...,\n",
      "          [ 1.5010, -0.2458,  0.7168,  ...,  0.5827,    -inf,    -inf],\n",
      "          [-0.1710, -1.4837, -0.3474,  ..., -0.1601, -0.4154,    -inf],\n",
      "          [ 0.7716, -0.1286,  0.6099,  ...,  0.6291,  0.6118, -0.0400]],\n",
      "\n",
      "         [[ 2.5172,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n",
      "          [ 2.2640,  1.8997,    -inf,  ...,    -inf,    -inf,    -inf],\n",
      "          [ 1.7125,  0.4181,  0.5325,  ...,    -inf,    -inf,    -inf],\n",
      "          ...,\n",
      "          [ 0.8620,  0.1433, -0.3180,  ..., -0.5638,    -inf,    -inf],\n",
      "          [ 2.5852,  0.9886,  0.7485,  ...,  0.2895,  1.3553,    -inf],\n",
      "          [ 2.6614,  0.7133,  0.1377,  ...,  1.0797,  1.5184,  1.2111]],\n",
      "\n",
      "         [[-0.4834,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n",
      "          [-0.1843,  0.6380,    -inf,  ...,    -inf,    -inf,    -inf],\n",
      "          [-1.6964, -0.7096, -0.3109,  ...,    -inf,    -inf,    -inf],\n",
      "          ...,\n",
      "          [-1.1913, -0.2825,  0.0828,  ..., -0.0317,    -inf,    -inf],\n",
      "          [-0.9114, -0.4782,  0.5929,  ...,  0.0868, -0.4815,    -inf],\n",
      "          [-0.1785,  0.3592,  1.3405,  ...,  0.5292, -0.4437,  0.5370]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8198,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n",
      "          [ 0.3198,  0.4227,    -inf,  ...,    -inf,    -inf,    -inf],\n",
      "          [-1.1084, -0.3118, -1.0385,  ...,    -inf,    -inf,    -inf],\n",
      "          ...,\n",
      "          [ 1.0528,  1.4714,  0.7978,  ...,  0.6807,    -inf,    -inf],\n",
      "          [-0.9137, -0.3273, -0.3247,  ..., -1.0340, -0.4237,    -inf],\n",
      "          [ 0.3194,  0.8475, -0.1027,  ..., -1.0311,  0.3452, -0.2791]],\n",
      "\n",
      "         [[-2.4567,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n",
      "          [-1.7414, -0.9326,    -inf,  ...,    -inf,    -inf,    -inf],\n",
      "          [-2.3011, -2.4102, -1.7097,  ...,    -inf,    -inf,    -inf],\n",
      "          ...,\n",
      "          [-1.0625, -1.3025, -0.3654,  ..., -0.3564,    -inf,    -inf],\n",
      "          [-1.9548, -1.6391, -1.2504,  ..., -1.2670, -1.6975,    -inf],\n",
      "          [-1.1760,  0.1062,  0.3455,  ..., -0.3675,  0.1087, -0.3722]],\n",
      "\n",
      "         [[-0.6161,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n",
      "          [-0.9114, -1.9956,    -inf,  ...,    -inf,    -inf,    -inf],\n",
      "          [-0.7861, -1.4164, -0.8317,  ...,    -inf,    -inf,    -inf],\n",
      "          ...,\n",
      "          [ 0.4981, -1.1914, -0.3489,  ..., -0.4914,    -inf,    -inf],\n",
      "          [-1.0851, -1.8641, -1.5070,  ..., -1.1570, -0.5289,    -inf],\n",
      "          [-0.6733, -1.3870, -0.9076,  ..., -1.2018, -0.4010, -0.6149]],\n",
      "\n",
      "         [[ 0.6650,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n",
      "          [ 0.0654, -2.9037,    -inf,  ...,    -inf,    -inf,    -inf],\n",
      "          [ 0.8012, -1.6186,  0.6033,  ...,    -inf,    -inf,    -inf],\n",
      "          ...,\n",
      "          [-0.1537, -2.1037, -0.2162,  ..., -1.0920,    -inf,    -inf],\n",
      "          [-0.3998, -2.3642, -0.1103,  ..., -1.3699, -0.7320,    -inf],\n",
      "          [ 0.1889, -2.1188,  0.5064,  ..., -0.6466,  0.0296, -1.2222]],\n",
      "\n",
      "         [[ 1.7169,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n",
      "          [ 0.7159,  0.5284,    -inf,  ...,    -inf,    -inf,    -inf],\n",
      "          [ 1.2111,  0.9619,  0.1847,  ...,    -inf,    -inf,    -inf],\n",
      "          ...,\n",
      "          [ 1.3949,  0.3734, -0.6634,  ...,  0.1450,    -inf,    -inf],\n",
      "          [ 0.8346,  0.9115,  1.0178,  ...,  0.6119,  0.0463,    -inf],\n",
      "          [ 1.5888,  1.0132,  0.9930,  ...,  0.9701,  0.3039,  1.9834]],\n",
      "\n",
      "         [[-0.3291,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n",
      "          [ 0.0865, -0.0260,    -inf,  ...,    -inf,    -inf,    -inf],\n",
      "          [-1.2858, -1.4529, -1.1956,  ...,    -inf,    -inf,    -inf],\n",
      "          ...,\n",
      "          [ 0.4599, -0.3012, -0.2018,  ...,  0.1719,    -inf,    -inf],\n",
      "          [ 0.3015,  0.2622,  0.5156,  ...,  0.6450,  1.2545,    -inf],\n",
      "          [-0.5019, -0.3460, -0.4588,  ..., -0.3637, -0.3562,  0.4633]]],\n",
      "\n",
      "\n",
      "        [[[-0.6317,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n",
      "          [-0.4724,  0.7441,    -inf,  ...,    -inf,    -inf,    -inf],\n",
      "          [-0.8167,  0.3863, -0.8025,  ...,    -inf,    -inf,    -inf],\n",
      "          ...,\n",
      "          [-0.7036,  0.7648, -0.0595,  ...,  0.0071,    -inf,    -inf],\n",
      "          [ 0.1258,  1.5224,  0.5104,  ...,  0.5038,  0.3888,    -inf],\n",
      "          [-1.3966, -0.2714, -0.8456,  ..., -0.6534, -0.0333, -0.6550]],\n",
      "\n",
      "         [[-1.4526,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n",
      "          [-1.9134, -0.4331,    -inf,  ...,    -inf,    -inf,    -inf],\n",
      "          [-1.6829, -0.4309, -1.3097,  ...,    -inf,    -inf,    -inf],\n",
      "          ...,\n",
      "          [-1.6865,  0.5315, -1.1758,  ..., -1.7452,    -inf,    -inf],\n",
      "          [-1.6907, -0.4612, -0.5759,  ..., -1.4188, -0.8065,    -inf],\n",
      "          [-1.0972, -0.1219, -0.1584,  ..., -1.4402, -0.4126, -0.3180]],\n",
      "\n",
      "         [[ 1.0293,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n",
      "          [-0.7203, -0.1241,    -inf,  ...,    -inf,    -inf,    -inf],\n",
      "          [-1.7637, -1.1515, -2.4411,  ...,    -inf,    -inf,    -inf],\n",
      "          ...,\n",
      "          [-1.0593, -0.3354, -0.9192,  ..., -0.8455,    -inf,    -inf],\n",
      "          [-0.9636, -0.6650, -0.6205,  ..., -1.1080, -0.8656,    -inf],\n",
      "          [-0.6682, -0.7124, -1.2081,  ..., -1.0218, -0.9457, -1.4825]],\n",
      "\n",
      "         [[ 0.3401,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n",
      "          [-0.1585,  0.3478,    -inf,  ...,    -inf,    -inf,    -inf],\n",
      "          [-1.2377, -0.7639, -0.5247,  ...,    -inf,    -inf,    -inf],\n",
      "          ...,\n",
      "          [-0.5013, -0.1088,  0.2525,  ..., -1.4241,    -inf,    -inf],\n",
      "          [-0.9055, -0.1660, -0.2118,  ..., -1.8575, -1.4191,    -inf],\n",
      "          [-0.7809,  0.7751, -0.9403,  ..., -1.4928,  0.2525, -0.1862]],\n",
      "\n",
      "         [[ 0.0119,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n",
      "          [ 1.4652,  0.3694,    -inf,  ...,    -inf,    -inf,    -inf],\n",
      "          [-0.3028, -0.9546,  1.2345,  ...,    -inf,    -inf,    -inf],\n",
      "          ...,\n",
      "          [ 0.2628, -0.4860,  2.1348,  ..., -0.4354,    -inf,    -inf],\n",
      "          [-0.5653,  0.0162,  2.0665,  ...,  0.4180,  1.0747,    -inf],\n",
      "          [ 0.6510,  0.7538,  2.5640,  ...,  0.8649,  0.9962,  1.5440]],\n",
      "\n",
      "         [[-0.6104,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n",
      "          [-0.2111,  1.3612,    -inf,  ...,    -inf,    -inf,    -inf],\n",
      "          [-0.6327,  1.4292,  0.0278,  ...,    -inf,    -inf,    -inf],\n",
      "          ...,\n",
      "          [-1.0236,  1.0172, -0.1811,  ..., -0.0130,    -inf,    -inf],\n",
      "          [ 0.7556,  2.5713,  1.4854,  ...,  1.2928,  1.1768,    -inf],\n",
      "          [ 0.4380,  1.8403,  1.1065,  ...,  1.0332,  0.8586,  0.9533]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n"
     ]
    }
   ],
   "source": [
    "test = mod(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = mod.W_key(x)\n",
    "queries = mod.W_query(x)\n",
    "values = mod.W_value(x)\n",
    "\n",
    "# We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "keys = keys.view(b, num_tokens, mod.num_heads, mod.head_dim)\n",
    "values = values.view(b, num_tokens, mod.num_heads, mod.head_dim)\n",
    "queries = queries.view(b, num_tokens, mod.num_heads, mod.head_dim)\n",
    "\n",
    "keys = keys.transpose(1, 2)\n",
    "queries = queries.transpose(1, 2)\n",
    "values = values.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1161, -0.0640,  0.1574,  ...,  0.2085,  0.1012, -0.1956],\n",
       "        [ 0.1173, -0.0626,  0.1569,  ...,  0.2088,  0.1014, -0.1943],\n",
       "        [ 0.1169, -0.0623,  0.1561,  ...,  0.2087,  0.1001, -0.1940],\n",
       "        ...,\n",
       "        [ 0.1164, -0.0620,  0.1552,  ...,  0.2089,  0.1013, -0.1949],\n",
       "        [ 0.1185, -0.0630,  0.1575,  ...,  0.2050,  0.1004, -0.1913],\n",
       "        [ 0.1157, -0.0629,  0.1573,  ...,  0.2075,  0.1015, -0.1941]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 3.9036e-01, -6.1331e-01,  5.6162e-01,  ...,  5.3590e-01,\n",
       "           -1.5826e-01, -3.4378e-01],\n",
       "          [ 3.8729e-01, -4.0058e-01,  2.9023e-01,  ...,  4.3854e-01,\n",
       "           -1.0273e-01, -7.6853e-01],\n",
       "          [ 4.0646e-01, -5.2343e-01,  3.4935e-01,  ...,  3.8613e-01,\n",
       "           -2.0635e-01, -6.1847e-01],\n",
       "          ...,\n",
       "          [ 4.2612e-01, -3.8096e-01,  1.6191e-01,  ...,  7.0502e-01,\n",
       "           -3.6284e-01, -5.4460e-01],\n",
       "          [ 7.0977e-01, -7.2567e-01,  4.4282e-01,  ...,  3.9433e-01,\n",
       "           -4.5750e-01, -3.1949e-01],\n",
       "          [ 7.6468e-01, -6.6319e-01,  6.3531e-01,  ...,  3.7257e-01,\n",
       "            1.2986e-02, -4.6432e-01]],\n",
       "\n",
       "         [[-1.0813e-01, -1.7516e-01,  3.0420e-01,  ...,  4.0926e-01,\n",
       "           -1.2339e-01, -2.7586e-01],\n",
       "          [ 4.2742e-01, -2.7741e-01,  7.5614e-02,  ...,  5.8028e-01,\n",
       "           -1.4355e-01,  1.4073e-01],\n",
       "          [ 3.8670e-01,  9.4920e-02,  4.1481e-01,  ...,  2.0570e-01,\n",
       "            5.8262e-03,  6.7882e-02],\n",
       "          ...,\n",
       "          [ 1.5628e-01,  5.0486e-02,  3.3751e-01,  ...,  9.4545e-02,\n",
       "           -1.5466e-01, -9.2425e-02],\n",
       "          [ 1.2130e-01, -3.9404e-02,  3.2103e-01,  ...,  2.6243e-01,\n",
       "           -1.2443e-01, -1.7007e-01],\n",
       "          [ 4.6665e-01,  1.8949e-03,  6.0845e-02,  ...,  4.5873e-01,\n",
       "           -8.8190e-02,  5.7516e-02]],\n",
       "\n",
       "         [[ 2.3434e-01,  1.7940e-01, -8.2198e-01,  ...,  3.3447e-01,\n",
       "           -1.4843e-01, -2.3782e-01],\n",
       "          [ 3.8191e-01, -1.2087e-01, -7.6999e-01,  ...,  3.7809e-01,\n",
       "           -3.1345e-01, -4.4687e-01],\n",
       "          [ 1.6359e-01, -2.5728e-02, -7.9891e-01,  ...,  1.2364e-01,\n",
       "           -4.0968e-01, -2.6671e-01],\n",
       "          ...,\n",
       "          [ 2.8224e-01,  5.1752e-04, -9.2490e-01,  ...,  5.2235e-02,\n",
       "           -4.2676e-01, -2.4977e-01],\n",
       "          [ 5.1447e-01,  3.4726e-02, -6.0340e-01,  ...,  2.3263e-01,\n",
       "           -5.7905e-01, -3.4924e-01],\n",
       "          [ 4.5388e-01, -9.2173e-02, -6.5519e-01,  ...,  1.1389e-01,\n",
       "           -1.1305e-01, -7.0935e-01]],\n",
       "\n",
       "         [[ 1.5902e-01, -2.0974e-01, -1.0368e-01,  ..., -1.2968e-01,\n",
       "            1.7597e-01,  1.8019e-01],\n",
       "          [-2.0794e-01, -4.8084e-01, -1.6802e-01,  ..., -2.9733e-01,\n",
       "            4.3231e-02, -2.2692e-02],\n",
       "          [-1.5474e-01, -3.6052e-01, -3.4904e-01,  ..., -2.0719e-01,\n",
       "            1.4756e-01, -3.9761e-01],\n",
       "          ...,\n",
       "          [ 3.7706e-02, -2.0606e-01, -9.4779e-03,  ..., -2.8690e-01,\n",
       "            3.2526e-01, -2.1517e-01],\n",
       "          [ 1.7798e-01,  2.3821e-02, -3.5321e-01,  ...,  6.6325e-02,\n",
       "            1.2140e-01, -4.8795e-01],\n",
       "          [-4.4142e-02,  6.8894e-02, -3.5241e-01,  ..., -6.9618e-02,\n",
       "            5.1183e-01,  3.6766e-02]],\n",
       "\n",
       "         [[-3.1957e-02,  3.8504e-01, -4.6342e-02,  ...,  1.5324e-01,\n",
       "            4.4618e-01, -3.6916e-01],\n",
       "          [-2.1177e-01,  1.6618e-02,  1.9646e-01,  ...,  9.0333e-02,\n",
       "            5.4852e-01, -2.6443e-01],\n",
       "          [ 4.8805e-02, -1.9465e-01, -1.3449e-01,  ..., -1.0398e-01,\n",
       "            3.9741e-01, -3.7423e-01],\n",
       "          ...,\n",
       "          [-4.8505e-02,  1.7479e-01,  1.4369e-01,  ..., -4.7633e-01,\n",
       "            5.0893e-01, -4.8525e-01],\n",
       "          [-2.5053e-02,  1.9099e-01,  1.5026e-01,  ..., -1.8078e-01,\n",
       "            7.3497e-01, -1.2623e-01],\n",
       "          [ 9.4116e-03,  3.9044e-01,  6.5321e-02,  ..., -5.6782e-02,\n",
       "            3.7152e-01, -3.8343e-01]],\n",
       "\n",
       "         [[ 5.1175e-01, -2.6621e-01,  5.0109e-01,  ...,  5.5914e-02,\n",
       "            2.8403e-01,  5.3386e-01],\n",
       "          [ 5.5687e-01, -1.3448e-02,  5.8248e-01,  ...,  4.8795e-02,\n",
       "            3.7348e-01,  3.9724e-01],\n",
       "          [ 3.0612e-01, -1.0687e-01,  5.4185e-01,  ...,  8.4099e-02,\n",
       "            9.6583e-02,  6.7307e-01],\n",
       "          ...,\n",
       "          [ 6.6595e-01, -7.5078e-02,  8.3953e-01,  ..., -3.2310e-02,\n",
       "            2.7455e-01,  6.7456e-01],\n",
       "          [ 4.0968e-01,  2.9545e-02,  4.7152e-01,  ..., -9.4922e-02,\n",
       "            2.9105e-01,  4.5152e-01],\n",
       "          [ 2.7518e-01,  3.0951e-01,  4.5875e-01,  ..., -1.1885e-01,\n",
       "           -2.5722e-01,  6.2759e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 4.6054e-01, -1.1115e-01,  5.3921e-01,  ...,  4.3949e-01,\n",
       "           -5.7778e-02, -4.7408e-01],\n",
       "          [ 5.3317e-01, -3.8877e-01,  5.2890e-01,  ...,  6.8000e-01,\n",
       "           -3.1760e-01, -6.5375e-01],\n",
       "          [ 5.7727e-01, -5.4077e-01,  2.2945e-01,  ...,  1.7292e-01,\n",
       "           -3.6846e-01, -1.0925e-01],\n",
       "          ...,\n",
       "          [ 6.5248e-01, -4.4703e-01,  1.8977e-01,  ...,  4.2221e-01,\n",
       "            8.8833e-02, -3.2889e-01],\n",
       "          [ 7.8706e-01, -5.8186e-01, -3.4986e-02,  ...,  3.0631e-01,\n",
       "            1.2962e-01, -3.3507e-01],\n",
       "          [ 6.5572e-01, -3.5292e-01,  2.8867e-01,  ...,  6.2110e-01,\n",
       "           -6.7446e-02, -4.3703e-01]],\n",
       "\n",
       "         [[ 4.5793e-01,  3.6463e-02,  1.7942e-01,  ..., -8.3070e-03,\n",
       "           -2.2010e-01, -9.8099e-02],\n",
       "          [ 1.5462e-01, -4.7235e-02,  2.9366e-01,  ...,  1.5605e-01,\n",
       "            1.0059e-01, -2.1253e-01],\n",
       "          [ 2.8323e-01, -1.3865e-01,  4.6413e-01,  ...,  7.2734e-01,\n",
       "           -2.9633e-01,  1.6888e-01],\n",
       "          ...,\n",
       "          [ 3.3863e-01, -8.9815e-02,  3.7042e-01,  ..., -5.1621e-02,\n",
       "           -2.8746e-02,  9.1606e-02],\n",
       "          [ 4.4780e-01,  1.8244e-01,  1.3939e-01,  ...,  3.4613e-01,\n",
       "            7.3658e-02, -4.2537e-02],\n",
       "          [ 3.9864e-01, -1.5189e-01,  8.8074e-02,  ...,  2.9075e-01,\n",
       "           -1.9813e-01, -1.5668e-01]],\n",
       "\n",
       "         [[ 3.5727e-01, -1.2908e-01, -2.5976e-01,  ...,  1.2490e-01,\n",
       "           -5.2867e-01, -4.1591e-01],\n",
       "          [ 3.8710e-01, -9.3353e-02, -6.7429e-01,  ...,  3.7601e-01,\n",
       "           -4.4233e-01, -5.3276e-01],\n",
       "          [ 4.6030e-01, -3.2928e-01, -5.6957e-01,  ...,  2.7206e-01,\n",
       "           -3.4522e-01, -4.9535e-01],\n",
       "          ...,\n",
       "          [ 3.8617e-01,  3.1757e-01, -4.4779e-01,  ...,  2.5030e-01,\n",
       "           -4.3927e-01, -2.6690e-01],\n",
       "          [ 2.3435e-01,  1.2322e-01, -6.6072e-01,  ...,  2.9413e-01,\n",
       "           -5.9815e-01, -2.8238e-01],\n",
       "          [ 2.5280e-01,  3.3699e-02, -4.5541e-01,  ...,  1.9557e-01,\n",
       "           -4.9015e-01, -2.1390e-01]],\n",
       "\n",
       "         [[-6.0218e-02, -2.2180e-01, -1.2645e-01,  ..., -2.5715e-02,\n",
       "            1.7023e-01, -7.1258e-03],\n",
       "          [-2.3295e-01, -5.1644e-01, -2.8636e-01,  ..., -3.0029e-01,\n",
       "           -1.1279e-01, -3.3395e-01],\n",
       "          [ 4.7249e-01, -3.6726e-01, -2.5933e-01,  ...,  8.5722e-02,\n",
       "           -3.1020e-03, -2.6025e-02],\n",
       "          ...,\n",
       "          [ 7.5612e-02,  8.8099e-02, -2.8109e-01,  ...,  3.1146e-02,\n",
       "            1.6116e-01, -9.8821e-02],\n",
       "          [ 1.9080e-01, -2.3669e-01, -3.4339e-01,  ...,  1.3879e-01,\n",
       "            2.2009e-01, -2.8269e-01],\n",
       "          [-1.1366e-01, -2.3399e-01, -5.4893e-01,  ..., -2.9234e-01,\n",
       "           -1.7933e-01, -2.4892e-01]],\n",
       "\n",
       "         [[ 8.7884e-02,  3.4287e-01,  3.3174e-01,  ...,  3.1771e-01,\n",
       "            6.3030e-01, -1.4759e-01],\n",
       "          [ 3.2082e-02,  3.7096e-01,  4.1314e-01,  ..., -9.6534e-02,\n",
       "            3.0998e-01, -2.6585e-01],\n",
       "          [-1.9157e-01,  5.9049e-02,  2.7592e-01,  ..., -1.0022e-01,\n",
       "            3.7265e-01, -1.9920e-01],\n",
       "          ...,\n",
       "          [ 3.6737e-01,  1.4092e-02, -1.5585e-01,  ..., -1.1284e-01,\n",
       "            6.2834e-01, -2.7795e-01],\n",
       "          [-1.7134e-01,  2.0222e-01,  4.0278e-02,  ...,  7.4045e-02,\n",
       "            2.6280e-01, -4.3614e-01],\n",
       "          [ 1.8795e-02,  4.5492e-02,  1.8790e-01,  ..., -1.2938e-01,\n",
       "            5.5452e-01, -1.3565e-01]],\n",
       "\n",
       "         [[ 1.1614e-01,  1.4213e-01,  7.3273e-01,  ..., -1.3452e-01,\n",
       "            1.2350e-01,  5.8667e-01],\n",
       "          [ 3.8393e-01,  1.5539e-01,  5.8109e-01,  ...,  1.3219e-01,\n",
       "            2.9084e-02,  5.9343e-01],\n",
       "          [ 5.0127e-01,  3.4298e-02,  8.1153e-01,  ..., -3.2228e-01,\n",
       "            3.2298e-01,  6.0517e-01],\n",
       "          ...,\n",
       "          [ 3.4912e-01, -3.3514e-02,  5.6564e-01,  ..., -8.9787e-02,\n",
       "            2.9951e-01,  8.0987e-01],\n",
       "          [ 2.3179e-01, -3.2557e-02,  8.2024e-01,  ..., -1.7290e-02,\n",
       "            1.8783e-01,  6.8228e-01],\n",
       "          [ 1.7505e-01,  3.3945e-01,  6.2683e-01,  ..., -1.2483e-01,\n",
       "            1.5891e-01,  5.9101e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 5.7761e-01, -3.1031e-01,  5.5121e-01,  ...,  5.1258e-01,\n",
       "            7.8823e-03, -7.2536e-01],\n",
       "          [ 5.1210e-01, -5.4132e-01,  3.1312e-01,  ...,  2.6444e-01,\n",
       "           -2.9276e-01, -3.0107e-01],\n",
       "          [ 1.7789e-01, -2.0194e-01,  2.0668e-01,  ...,  4.3216e-01,\n",
       "           -4.0590e-01, -5.0390e-01],\n",
       "          ...,\n",
       "          [ 4.6213e-01, -3.1049e-01,  4.3552e-01,  ...,  5.2569e-01,\n",
       "           -1.9891e-01, -4.5135e-01],\n",
       "          [ 9.1903e-01, -3.1222e-01,  1.1888e-01,  ...,  4.0061e-01,\n",
       "            9.5089e-02, -4.4317e-01],\n",
       "          [ 5.0447e-01, -7.9611e-01,  4.6647e-01,  ...,  5.8556e-01,\n",
       "           -2.1034e-01, -6.8690e-01]],\n",
       "\n",
       "         [[ 9.4765e-02, -8.2316e-03,  4.1958e-01,  ...,  3.4622e-01,\n",
       "           -5.3650e-02, -1.2928e-01],\n",
       "          [ 2.5014e-01,  2.1048e-01,  5.6994e-01,  ...,  4.6739e-01,\n",
       "            1.9098e-02, -4.2752e-01],\n",
       "          [ 2.9124e-01,  9.9177e-02,  1.1616e-01,  ...,  4.2816e-01,\n",
       "            1.8797e-01,  1.1471e-02],\n",
       "          ...,\n",
       "          [ 4.0788e-01, -8.1981e-03,  5.2369e-01,  ...,  2.9887e-01,\n",
       "           -2.8111e-02, -2.3003e-01],\n",
       "          [ 5.3512e-01, -1.9653e-01,  2.6429e-02,  ...,  2.8860e-01,\n",
       "           -4.7147e-01, -1.0745e-02],\n",
       "          [ 5.2060e-01, -2.0733e-02,  3.1639e-01,  ...,  3.3054e-01,\n",
       "            2.0575e-02,  1.2150e-01]],\n",
       "\n",
       "         [[ 4.7430e-01,  5.4941e-01, -6.2340e-01,  ...,  5.4886e-01,\n",
       "           -4.9760e-01, -2.7033e-01],\n",
       "          [ 1.8094e-01,  1.0076e-01, -9.1505e-01,  ...,  2.6455e-01,\n",
       "           -1.8954e-01, -3.4876e-01],\n",
       "          [ 4.3131e-01,  1.2711e-01, -6.5739e-01,  ...,  4.3532e-01,\n",
       "           -4.1154e-01, -3.0621e-01],\n",
       "          ...,\n",
       "          [ 3.9830e-01, -5.2922e-02, -6.7081e-01,  ...,  3.6443e-01,\n",
       "           -3.0603e-01, -3.8546e-01],\n",
       "          [ 4.0912e-01,  2.5898e-02, -7.8429e-01,  ...,  4.7424e-01,\n",
       "           -3.6088e-01, -6.0103e-01],\n",
       "          [ 5.4817e-01,  3.2795e-02, -8.2101e-01,  ...,  3.8829e-01,\n",
       "           -6.0588e-01, -6.4932e-01]],\n",
       "\n",
       "         [[-3.8108e-01, -1.1968e-01,  1.1747e-02,  ...,  2.3904e-02,\n",
       "            3.4790e-01,  3.8609e-02],\n",
       "          [-1.7269e-01, -2.4296e-02, -2.6459e-01,  ..., -1.8144e-01,\n",
       "            1.8380e-01,  6.8177e-02],\n",
       "          [ 1.2139e-01, -4.4449e-01, -1.9863e-01,  ..., -2.4556e-01,\n",
       "           -7.9570e-02, -9.9575e-02],\n",
       "          ...,\n",
       "          [ 2.4696e-01, -2.6183e-01, -2.3216e-01,  ..., -1.9679e-01,\n",
       "            4.6982e-02, -2.7844e-01],\n",
       "          [-1.4664e-01, -2.4494e-01, -2.7233e-01,  ..., -1.7398e-01,\n",
       "            1.6443e-01, -9.8072e-02],\n",
       "          [ 1.4974e-01, -3.4100e-01, -3.1502e-01,  ..., -1.6783e-01,\n",
       "            4.4275e-02,  1.0334e-01]],\n",
       "\n",
       "         [[-1.4414e-01,  1.6473e-01,  1.1730e-01,  ..., -1.9272e-01,\n",
       "            6.2457e-01, -2.0726e-01],\n",
       "          [-2.4701e-01, -2.0395e-01,  1.9221e-01,  ..., -8.1465e-02,\n",
       "            4.8285e-01, -2.0339e-01],\n",
       "          [ 2.1470e-02,  1.5465e-01, -1.5391e-01,  ...,  2.8081e-01,\n",
       "            6.0975e-01, -8.1777e-02],\n",
       "          ...,\n",
       "          [ 1.5132e-01,  3.6610e-01,  1.6508e-01,  ...,  6.7164e-02,\n",
       "            5.7595e-01, -4.5649e-01],\n",
       "          [-2.1769e-02, -2.1256e-01, -2.4676e-01,  ..., -1.5344e-02,\n",
       "            4.6960e-01,  4.4881e-02],\n",
       "          [-3.2525e-01,  3.4373e-01,  3.7527e-01,  ...,  5.9656e-02,\n",
       "            3.9729e-01, -1.4916e-01]],\n",
       "\n",
       "         [[ 4.4330e-01,  1.4046e-01,  9.6217e-01,  ...,  1.8798e-01,\n",
       "            2.3847e-01,  6.4982e-01],\n",
       "          [ 3.1063e-01, -1.0173e-02,  3.0810e-01,  ..., -6.2341e-02,\n",
       "            2.6508e-01,  7.4372e-01],\n",
       "          [ 3.8679e-01,  2.2362e-01,  5.8029e-01,  ..., -1.2831e-01,\n",
       "            4.5339e-01,  5.4393e-01],\n",
       "          ...,\n",
       "          [ 4.1148e-01, -7.3391e-02,  8.7702e-01,  ...,  1.8689e-03,\n",
       "            1.3946e-01,  5.2538e-01],\n",
       "          [ 4.7454e-01, -1.6613e-01,  4.9418e-01,  ..., -2.9159e-01,\n",
       "            1.7841e-01,  3.4439e-01],\n",
       "          [ 6.8236e-01,  1.1658e-01,  6.6154e-01,  ..., -3.4493e-01,\n",
       "            2.6268e-01,  9.9940e-01]]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
